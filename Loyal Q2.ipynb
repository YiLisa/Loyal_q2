{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, cross_validate,StratifiedKFold,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_score,recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "with open('data/data_full.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for d in data['train']:\n",
    "        train.append(d)\n",
    "    for d in data['val']:\n",
    "        val.append(d)\n",
    "    for d in data['test']:\n",
    "        test.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Cleaning and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label = []\n",
    "for t in train:\n",
    "    val_label.append(t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set(val_label))\n",
    "selected_labels = []\n",
    "for i in range(20):\n",
    "    ind = random.randint(0,len(labels)-1)\n",
    "    selected_labels.append(labels[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for d in train:\n",
    "    if d[1] in selected_labels:\n",
    "        new_train.append(d)\n",
    "for d in val:\n",
    "    if d[1] in selected_labels:\n",
    "        new_val.append(d)\n",
    "for d in test:\n",
    "    if d[1] in selected_labels:\n",
    "        new_test.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame(new_train,columns =['Data', 'Label'])\n",
    "val_set = pd.DataFrame(new_val,columns =['Data', 'Label'])\n",
    "test_set = pd.DataFrame(new_test,columns =['Data', 'Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Creating and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression(penalty='l2',multi_class='multinomial',solver = 'lbfgs'))\n",
    "X_train = train_set['Data']\n",
    "X_val = val_set['Data']\n",
    "X_test = test_set['Data']\n",
    "Y_train = train_set['Label']\n",
    "Y_val = val_set['Label']\n",
    "Y_test = test_set['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                apr       0.95      1.00      0.98        20\n",
      "         calculator       0.95      0.95      0.95        20\n",
      " cancel_reservation       1.00      1.00      1.00        20\n",
      "           carry_on       1.00      1.00      1.00        20\n",
      "       credit_score       1.00      0.95      0.97        20\n",
      "     freeze_account       1.00      1.00      1.00        20\n",
      "            goodbye       0.91      1.00      0.95        20\n",
      "    how_old_are_you       1.00      1.00      1.00        20\n",
      "   ingredients_list       1.00      1.00      1.00        20\n",
      "              maybe       0.94      0.80      0.86        20\n",
      "   meeting_schedule       0.91      1.00      0.95        20\n",
      "          next_song       1.00      1.00      1.00        20\n",
      "    oil_change_when       1.00      1.00      1.00        20\n",
      "             recipe       1.00      1.00      1.00        20\n",
      "             repeat       0.90      0.90      0.90        20\n",
      "          tell_joke       0.95      0.95      0.95        20\n",
      "travel_notification       0.95      1.00      0.98        20\n",
      "                 w2       1.00      1.00      1.00        20\n",
      "            weather       1.00      0.90      0.95        20\n",
      "\n",
      "           accuracy                           0.97       380\n",
      "          macro avg       0.97      0.97      0.97       380\n",
      "       weighted avg       0.97      0.97      0.97       380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, Y_train)\n",
    "y_pred_class = pipeline.predict(X_val)\n",
    "print(classification_report(Y_val, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/loyal/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.05263158        nan 0.91885965 0.91885965 0.05263158        nan\n",
      " 0.91929825 0.91842105 0.05263158        nan 0.92192982 0.92982456\n",
      " 0.05263158        nan 0.9254386  0.93026316 0.05263158        nan\n",
      " 0.92894737 0.93114035 0.05263158        nan 0.93245614 0.93289474\n",
      " 0.175             nan 0.93377193 0.93552632 0.73289474        nan\n",
      " 0.94298246 0.94385965 0.86666667        nan 0.95307018 0.95350877\n",
      " 0.91315789        nan 0.95701754 0.95701754 0.94605263        nan\n",
      " 0.96491228 0.96622807 0.95482456        nan 0.96885965 0.96798246\n",
      " 0.95701754        nan 0.96973684 0.96973684 0.95701754        nan\n",
      " 0.97105263 0.97017544 0.95701754        nan 0.97105263 0.96929825\n",
      " 0.95657895        nan 0.97061404 0.96885965 0.95701754        nan\n",
      " 0.97061404 0.96929825 0.95789474        nan 0.96929825 0.97017544\n",
      " 0.96008772        nan 0.96929825 0.97105263 0.95964912        nan\n",
      " 0.96929825 0.96973684]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "params = {'logisticregression__penalty' : ['l1', 'l2'],\n",
    "    'logisticregression__C' : np.logspace(-4, 4, 20),\n",
    "    'logisticregression__solver' : ['liblinear','lbfgs']}\n",
    "clf = GridSearchCV(pipeline, param_grid = params, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(list(X_train)+list(X_val), list(Y_train)+list(Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                apr       1.00      1.00      1.00        30\n",
      "         calculator       0.97      0.97      0.97        30\n",
      " cancel_reservation       0.97      1.00      0.98        30\n",
      "           carry_on       1.00      0.97      0.98        30\n",
      "       credit_score       1.00      1.00      1.00        30\n",
      "     freeze_account       1.00      1.00      1.00        30\n",
      "            goodbye       0.97      0.97      0.97        30\n",
      "    how_old_are_you       0.97      1.00      0.98        30\n",
      "   ingredients_list       0.89      0.83      0.86        30\n",
      "              maybe       0.91      0.97      0.94        30\n",
      "   meeting_schedule       1.00      1.00      1.00        30\n",
      "          next_song       1.00      1.00      1.00        30\n",
      "    oil_change_when       1.00      1.00      1.00        30\n",
      "             recipe       0.84      0.90      0.87        30\n",
      "             repeat       1.00      0.93      0.97        30\n",
      "          tell_joke       1.00      1.00      1.00        30\n",
      "travel_notification       1.00      1.00      1.00        30\n",
      "                 w2       1.00      1.00      1.00        30\n",
      "            weather       1.00      0.97      0.98        30\n",
      "\n",
      "           accuracy                           0.97       570\n",
      "          macro avg       0.97      0.97      0.97       570\n",
      "       weighted avg       0.97      0.97      0.97       570\n",
      "\n",
      "Precision score : 0.9742986498504325\n",
      "Recall score  : 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = best_clf.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='weighted'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('classifier.sk','wb')\n",
    "pickle.dump(pipeline,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Questions:\n",
    "- I choice to use TfidfVectorizer to precess the text input. I think this is a better method compare to CountVectorizer because Tf-idf will weight more on less common words which may be more important for our classification.\n",
    "- Then I choice logistic regression to do this multi-class classification. Based on my experience with this kind of problems, I think logistic regression is always a good starting model. It is easy and quick to train and use, and it have a good result in most cases.\n",
    "- The model architecture is simply a Tfidf Vectorizer followed by loglogistic regression classifier. I used cross validation and hyperparameter tuning to improve the performance.\n",
    "- Since it is a classification problem, I use accuracy, precision, recall, and f1 score to evaluate the model. The weighted average accuracy is 0.97, weighted average precision is 0.9743, and weighted average recall is 0.9737. Therefore the f1 score = 2 * Precision * Recall / Presicion + Recall = 0.9740\n",
    "- There are potential improvement can be done in the future. I could try more classification models to pick the best model and extend the classifier to more classes and even out-of-scope classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
