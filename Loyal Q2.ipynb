{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, cross_validate,StratifiedKFold,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_score,recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "with open('/Users/yi/Documents/GitHub/oos-eval/data/data_full.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for d in data['train']:\n",
    "        train.append(d)\n",
    "    for d in data['val']:\n",
    "        val.append(d)\n",
    "    for d in data['test']:\n",
    "        test.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Cleaning and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label = []\n",
    "for t in train:\n",
    "    val_label.append(t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set(val_label))\n",
    "selected_labels = []\n",
    "for i in range(20):\n",
    "    ind = random.randint(0,len(labels)-1)\n",
    "    selected_labels.append(labels[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for d in train:\n",
    "    if d[1] in selected_labels:\n",
    "        new_train.append(d)\n",
    "for d in val:\n",
    "    if d[1] in selected_labels:\n",
    "        new_val.append(d)\n",
    "for d in test:\n",
    "    if d[1] in selected_labels:\n",
    "        new_test.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame(new_train,columns =['Data', 'Label'])\n",
    "val_set = pd.DataFrame(new_val,columns =['Data', 'Label'])\n",
    "test_set = pd.DataFrame(new_test,columns =['Data', 'Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Creating and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression(penalty='l2',multi_class='multinomial',solver = 'lbfgs'))\n",
    "X_train = train_set['Data']\n",
    "X_val = val_set['Data']\n",
    "X_test = test_set['Data']\n",
    "Y_train = train_set['Label']\n",
    "Y_val = val_set['Label']\n",
    "Y_test = test_set['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "             bill_due       1.00      1.00      1.00        20\n",
      "   cancel_reservation       1.00      1.00      1.00        20\n",
      "        card_declined       0.95      1.00      0.98        20\n",
      "        change_accent       1.00      0.75      0.86        20\n",
      "      change_language       0.87      1.00      0.93        20\n",
      "      meal_suggestion       1.00      0.95      0.97        20\n",
      "restaurant_suggestion       0.95      1.00      0.98        20\n",
      "      rewards_balance       1.00      1.00      1.00        20\n",
      "           smart_home       1.00      1.00      1.00        20\n",
      "     spending_history       1.00      1.00      1.00        20\n",
      "            tell_joke       1.00      1.00      1.00        20\n",
      "                 time       1.00      1.00      1.00        20\n",
      "            user_name       0.86      0.90      0.88        20\n",
      "    what_is_your_name       0.90      0.90      0.90        20\n",
      "   where_are_you_from       0.91      1.00      0.95        20\n",
      "  who_do_you_work_for       0.90      0.90      0.90        20\n",
      "         who_made_you       0.90      0.90      0.90        20\n",
      "                  yes       1.00      0.90      0.95        20\n",
      "\n",
      "             accuracy                           0.96       360\n",
      "            macro avg       0.96      0.96      0.96       360\n",
      "         weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, Y_train)\n",
    "y_pred_class = pipeline.predict(X_val)\n",
    "print(classification_report(Y_val, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/loyal/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.05555556        nan 0.89074074 0.89027778 0.05555556        nan\n",
      " 0.89305556 0.89074074 0.05555556        nan 0.89768519 0.91481481\n",
      " 0.05555556        nan 0.90277778 0.91527778 0.05555556        nan\n",
      " 0.90648148 0.91574074 0.05555556        nan 0.91203704 0.91527778\n",
      " 0.10833333        nan 0.91851852 0.91990741 0.64814815        nan\n",
      " 0.92916667 0.93055556 0.82314815        nan 0.93842593 0.93657407\n",
      " 0.9125            nan 0.95046296 0.95       0.93981481        nan\n",
      " 0.95462963 0.95555556 0.94953704        nan 0.96018519 0.95740741\n",
      " 0.95138889        nan 0.9625     0.95833333 0.95              nan\n",
      " 0.96157407 0.95925926 0.95046296        nan 0.96296296 0.96064815\n",
      " 0.95092593        nan 0.96296296 0.96157407 0.94907407        nan\n",
      " 0.96018519 0.9587963  0.95324074        nan 0.9587963  0.95833333\n",
      " 0.95046296        nan 0.95694444 0.95648148 0.94953704        nan\n",
      " 0.95787037 0.95509259]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "params = {'logisticregression__penalty' : ['l1', 'l2'],\n",
    "    'logisticregression__C' : np.logspace(-4, 4, 20),\n",
    "    'logisticregression__solver' : ['liblinear','lbfgs']}\n",
    "clf = GridSearchCV(pipeline, param_grid = params, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(list(X_train)+list(X_val), list(Y_train)+list(Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "             bill_due       0.97      1.00      0.98        30\n",
      "   cancel_reservation       1.00      1.00      1.00        30\n",
      "        card_declined       1.00      1.00      1.00        30\n",
      "        change_accent       1.00      1.00      1.00        30\n",
      "      change_language       0.93      0.93      0.93        30\n",
      "      meal_suggestion       0.91      0.97      0.94        30\n",
      "restaurant_suggestion       1.00      0.93      0.97        30\n",
      "      rewards_balance       1.00      1.00      1.00        30\n",
      "           smart_home       1.00      1.00      1.00        30\n",
      "     spending_history       1.00      0.90      0.95        30\n",
      "            tell_joke       0.97      1.00      0.98        30\n",
      "                 time       1.00      1.00      1.00        30\n",
      "            user_name       0.90      0.93      0.92        30\n",
      "    what_is_your_name       0.84      0.90      0.87        30\n",
      "   where_are_you_from       0.93      0.93      0.93        30\n",
      "  who_do_you_work_for       0.93      0.83      0.88        30\n",
      "         who_made_you       0.88      0.97      0.92        30\n",
      "                  yes       0.96      0.90      0.93        30\n",
      "\n",
      "             accuracy                           0.96       540\n",
      "            macro avg       0.96      0.96      0.96       540\n",
      "         weighted avg       0.96      0.96      0.96       540\n",
      "\n",
      "Precision score : 0.956909770171419\n",
      "Recall score  : 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = best_clf.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='weighted'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('classifier.sk','wb')\n",
    "pickle.dump(pipeline,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Questions:\n",
    "- I choice to use TfidfVectorizer to precess the text input. I think this is a better method compare to CountVectorizer because Tf-idf will weight more on less common words which may be more important for our classification.\n",
    "- Then I choice logistic regression to do this multi-class classification. Based on my experience with this kind of problems, I think logistic regression is always a good starting model. It is easy and quick to train and use, and it have a good result in most cases.\n",
    "- The model architecture is simply a Tfidf Vectorizer followed by loglogistic regression classifier. I used cross validation and hyperparameter tuning to improve the performance.\n",
    "- Since it is a classification problem, I use accuracy, precision, recall, and f1 score to evaluate the model. The weighted average accuracy is 0.96, weighted average precision is 0.9569, and weighted average recall is 0.9555. Therefore the f1 score = 2 * Precision * Recall / Presicion + Recall = 0.9562\n",
    "- There are potential improvement can be done in the future. I could try more classification models to pick the best model and extend the classifier to more classes and even out-of-scope classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
